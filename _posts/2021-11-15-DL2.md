---
layout: post
title: "DL2 : Optimization in Deep Learning ~ Gradient Descent Strategies"
date: 2021-11-15
image: /images/feed-forward-nn.jpeg
headerImage: false
tags: [optimization, learning rate] 
excerpt: Gradient Descent is a generic method that can be used to optimize any differtiable loss function and find its minimum. This blog post aims at giving readers a practical and yet an intuitive guide on the different strategies for optimizing gradient descent.
---

Neural networks are universal function approximators. This means that with suffcient neurons, they can approximate any function (convex or not) well. Learning problems can be formulated and modelled as non-convex optimization, where a global minimum may not necessariliy be the local minimum. In achieving this, many convex optimization techniques such as stochastic gradient descent (SGD), mini-batching, and momentum are used. However, convergence to a bad local minimum may happen and the system will have to be re-optimized with a different sset of initialization and weights.

The direction downwards to a given point is given by its derivative which is specified by the tangent line as seen in the image.

![image](https://user-images.githubusercontent.com/80447701/145985155-71bb02c2-0754-4604-b0b8-ae54d7605771.png)

This is how batch gradient descent looks like in code :

```shell
for i in range(nb_epochs):
  params_grad = evaluate_gradient(loss_function, data, params)
  params = params - learning_rate * params_grad
``` 


Deep Learning seeks to address the following 3 questions : 

![image](https://user-images.githubusercontent.com/80447701/146328286-23af9833-8261-4f5c-aa93-7116705bf2bd.png)



In conclusion, this is my summary and understanding of GD. Do you have any comments, suggestions or criticisms? Please send to üëá. If you like the article, please do share it with your friends ‚ù§Ô∏è. Who knows, it might come in use for someone else thinking along the same lines! üòâ
