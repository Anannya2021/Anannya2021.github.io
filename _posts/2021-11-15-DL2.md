---
layout: post
title: "DL2 : Optimization in Deep Learning ~ Gradient Descent Strategies"
date: 2021-11-15
image: /images/feed-forward-nn.jpeg
headerImage: false
tags: [optimization, learning rate] 
excerpt: Gradient Descent is a generic method that can be used to optimize any differtiable loss function and find its minimum. In this article i will take an in depth view of the heuristics around it...
---

There are 3 important components in building a neural network : 

1) Activation function - examples are sigmoid, tanh, Rectified Linear unit(relu) 
2) Loss Function - which is the proxy to obtaining the ideal parameters. Example is binary cross entropy for multi-class classification problem.
3) optimizer - finiding the optimal weights to the problem on hand. Examples are SGD, momentum, adam

In the case of a feed forward neural network, the idea is to stack multiple models to discover hidden patterns. The network is represented as a nested matrix

This blog pot aims at giving readers an intuitive guide on the different methods for optimizing gradient descent. For neural networks, gradient descent is the preferred algorithm for optimization. 
Convex optimization means that the objective function has a local minimum that is equal to its global minimum. Once a minimum is found through minimizing specific convex function over convex sets, we can say we have its global minimum with confidence. In this way since the minimum is only found once, it is less computational intensive and provides for a stable and exact output in an effcient manner. One deep learning library, [keras](https://keras.io/api/optimizers/) demonstrates the implementation of the GD algorithm but it is however used as a black box optimizer during training. Mathemetically, we can represent a course function as : 

![image](https://user-images.githubusercontent.com/80447701/146341247-2da6a740-063f-426a-b2e5-30b4194bca14.png)

Source image 1 : Coursera

The direction downwards to a given point is given by its derivative which is specified by the tangent line as seen in the image.

![image](https://user-images.githubusercontent.com/80447701/145985155-71bb02c2-0754-4604-b0b8-ae54d7605771.png)

This is how batch gradient descent looks like in code :

```shell
for i in range(nb_epochs):
  params_grad = evaluate_gradient(loss_function, data, params)
  params = params - learning_rate * params_grad
``` 


Deep Learning seeks to address the following 3 questions : 

![image](https://user-images.githubusercontent.com/80447701/146328286-23af9833-8261-4f5c-aa93-7116705bf2bd.png)

Neural networks are universal function approximators. This means that with suffcient neurons, they can approximate any function (convex or not) well. Learning problems can be formulated and modelled as non-convex optimization. In achieving this, many convex optimization techniques such as stochastic gradient descent (SGD), mini-batching, and momentum are used. However, convergence to a bad local minimum may happen and the system will have to be re-optimized with a different sset of initialization and weights.

In conclusion, this is my summary and understanding of GD. Do you have any comments, suggestions or criticisms? Please send to üëá. If you like the article, please do share it with your friends ‚ù§Ô∏è. Who knows, it might come in use for someone else thinking along the same lines! üòâ
