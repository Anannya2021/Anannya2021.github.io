---
layout: post
title: "DL2 : Deep Learning Methods ~ Analyzing the Classes of Neural Networks"
date: 2021-12-1
---
In this blog, i will attempt to explain why we gravitate away from the traditional machine learning methods and focus on the important type of neural network models that form the basis for most of our pre-trianed models in deep learning. 

1) ANN
2) RNN
3) CNN

RNN, a class of deep learning method, was first designed to help predict sequences. They work on data sequences of the variable input length. It puts the knowledge gained from the previous state as an input value for the current prediction. While it has been used in the management of stock price changes, it is a technique that can also be used to predict consumer behaviour from their interaction history. Consumer history can be viewed as a sequence of events. It captures and holds important important clues that can be used for predictions. For example, we may want to find out the propensity of a customer to order within the next 7 days, from the time they engaged and viewed the product. 

There are two types of RNNs which are useful in prediction of time sequences via memory, LSTM and Gated RNN. LSTM is Long Short Term memory and it has 3 gates : Input / Output and Forget.

Traditionally, feature engineering was applied on sequential data through machine learning models. In feature engineering, a vector of features are constructed from a given 
consumer history and this is provided as an input to a vector based machine learning model. Deciding on the exact choice of feature representation has decisive effects on a 
model's performance and it is a tedious and laborious work, so an alternative to circumvent this is to look towards recurrent neural networks as they work directly on sequences 
as inputs.

