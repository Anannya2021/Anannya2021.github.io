---
layout: post
title: "ML3 : Handling Model Drift ~ Cues for Retraining and Incremental Learning"
date: 2022-01-16
excerpt: Monitoring machine learning models in production is a necessary but tedious task. When the data has changed and the model has drifted, it will impact the model performance. 
---

Models in production need to keep up with the reality of real world representation and business processes in order to meet the performance metrics realized in development or risk failing over time in providing predictions and insights that are useful to the business. One good example is with the covid19 pandemic, ecommerce and retail behaviours changed drastically. Models such as the propensity to buy that were constructed by relying on previous business assumptions required retraining to retain impact the AI value. Introduction of new features into a product that are not included in the model will alter its performance and possibly cause the business to degrade over time as well. Therein lies the question, how do we observe and overcome a model performance dip, also known as error rate based on drift detection?

One strategy leans on detecting drift through comparing statistical distribution of features values used in training versus that in production. More often than not, after deploying a model, the prediction input data deviates from the data that the model was trained on. <TBC>
